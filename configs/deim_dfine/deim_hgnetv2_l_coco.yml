__include__: [
  './dfine_hgnetv2_l_coco.yml',
  '../base/deim.yml'
]

output_dir: ./outputs/deim_hgnetv2_l_coco

optimizer:
  type: AdamW
  params: 
    - 
      params: '^(?=.*backbone)(?!.*norm|bn).*$'
      lr: 0.000025
    - 
      params: '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$'
      weight_decay: 0.

  lr: 0.0005
  betas: [0.9, 0.999]
  weight_decay: 0.000125
  
# Increase to search for the optimal ema
epoches: 30 # 72 + 2n

## Our LR-Scheduler
flat_epoch: 19    # 4 + epoch // 2, e.g., 40 = 4 + 72 / 2
no_aug_epoch: 20

train_dataloader: 
  dataset: 
    transforms:
      policy:
        epoch: [4, 19, 24]   # list

  collate_fn:
    mixup_epochs: [4, 19]
    stop_epoch: 20